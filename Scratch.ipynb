{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dcd4a84",
   "metadata": {},
   "source": [
    "## APP PASSWORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_PASSWORD = 'hksx zxjb wztw ncvp'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb48a647",
   "metadata": {},
   "source": [
    "## Ebay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e66a160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sender: eBay <ebay@ebay.com>\n",
      "Subject: Da, your order is confirmed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('BYE', [b'LOGOUT Requested'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imaplib\n",
    "import email\n",
    "from email.header import decode_header\n",
    "\n",
    "# IMAP server settings for Gmail\n",
    "IMAP_SERVER = 'imap.gmail.com'\n",
    "USERNAME = 'dateng2016@gmail.com'\n",
    "PASSWORD = APP_PASSWORD\n",
    "\n",
    "# Connect to the IMAP server\n",
    "mail = imaplib.IMAP4_SSL(IMAP_SERVER)\n",
    "mail.login(USERNAME, PASSWORD)\n",
    "\n",
    "# Select the mailbox (e.g., 'INBOX')\n",
    "mail.select('INBOX')\n",
    "\n",
    "# Search for emails based on specific criteria (e.g., subject, sender, date)\n",
    "search_criteria = '(SUBJECT \"Da, your order is confirmed\")'\n",
    "result, data = mail.search(None, search_criteria)\n",
    "\n",
    "# Get the email IDs\n",
    "email_ids = data[0].split()\n",
    "\n",
    "# Retrieve the most recent email (assuming the search returns emails sorted by date)\n",
    "latest_email_id = email_ids[-1]\n",
    "\n",
    "# Fetch the email data (headers and body)\n",
    "result, email_data = mail.fetch(latest_email_id, '(RFC822)')\n",
    "raw_email = email_data[0][1]\n",
    "\n",
    "# Parse the raw email data\n",
    "msg = email.message_from_bytes(raw_email)\n",
    "\n",
    "# Extract email information (e.g., sender, subject)\n",
    "sender = msg['From']\n",
    "subject = decode_header(msg['Subject'])[0][0]\n",
    "\n",
    "# Print email information\n",
    "print(\"Sender:\", sender)\n",
    "print(\"Subject:\", subject)\n",
    "\n",
    "# You can access email body and attachments similarly\n",
    "# body = msg.get_payload()\n",
    "\n",
    "# Function to get the email body\n",
    "def get_email_body(msg):\n",
    "    if msg.is_multipart():\n",
    "        # If the message is multipart, iterate over each part\n",
    "        for part in msg.walk():\n",
    "            content_type = part.get_content_type()\n",
    "            if content_type == \"text/plain\" or content_type == \"text/html\":\n",
    "                # If the part is plain text or HTML, return its payload\n",
    "                return part.get_payload(decode=True).decode()\n",
    "    else:\n",
    "        # If the message is not multipart, return its payload\n",
    "        return msg.get_payload(decode=True).decode()\n",
    "\n",
    "# Example usage:\n",
    "email_body = get_email_body(msg)\n",
    "# print(\"Email Body:\", email_body)\n",
    "\n",
    "\n",
    "# Close the connection\n",
    "mail.close()\n",
    "mail.logout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6b34034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merchant name: eBay\n",
      "\n",
      "Item:  \n",
      "3.5mm Jack To 2 Rca Stereo Audio Cable Adapter 6ft 10...\n",
      "\n",
      "Price:  \n",
      "$5.07\n",
      "\n",
      "Date:  Tue, 13 Feb 2024 17:33:11 -0700\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(email_body, 'html.parser')\n",
    "\n",
    "name_tag = soup.find('a', class_='title')\n",
    "price_tags = soup.find_all('td', class_=\"item\")\n",
    "print(f'Merchant name: {sender.split(\" \")[0]}')\n",
    "print()\n",
    "print('Item: ', name_tag.string)\n",
    "print('Price: ',price_tags[-1].string)\n",
    "print('Date: ', msg['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1930592b",
   "metadata": {},
   "source": [
    "## Gmail API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "706e2a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving HTML to ReceiptFolder/index1.html\n",
      "Amazon\n",
      "Thu, 8 Feb 2024 00:01:07 +0000\n",
      "Saving HTML to ReceiptFolder/index2.html\n",
      "Amazon\n",
      "Wed, 7 Feb 2024 19:10:36 +0000\n",
      "Saving HTML to ReceiptFolder/index3.html\n",
      "Amazon\n",
      "Tue, 19 Dec 2023 23:56:35 +0000\n",
      "Saving HTML to ReceiptFolder/index4.html\n",
      "Amazon\n",
      "Fri, 20 Oct 2023 01:25:00 +0000\n",
      "Saving HTML to ReceiptFolder/index5.html\n",
      "Amazon\n",
      "Fri, 13 Oct 2023 18:39:33 +0000\n",
      "Saving HTML to ReceiptFolder/index6.html\n",
      "Amazon\n",
      "Mon, 21 Aug 2023 02:03:10 +0000\n",
      "Saving HTML to ReceiptFolder/index7.html\n",
      "Amazon\n",
      "Mon, 21 Aug 2023 01:58:30 +0000\n",
      "Saving HTML to ReceiptFolder/index8.html\n",
      "Amazon\n",
      "Wed, 3 May 2023 00:03:55 +0000\n",
      "Saving HTML to ReceiptFolder/index9.html\n",
      "Amazon\n",
      "Fri, 28 Apr 2023 00:25:00 +0000\n",
      "Saving HTML to ReceiptFolder/index10.html\n",
      "Amazon\n",
      "Thu, 2 Mar 2023 00:27:31 +0000\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# for encoding/decoding messages in base64\n",
    "from base64 import urlsafe_b64decode\n",
    "\n",
    "# for dealing with attachement MIME types\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "# If modifying these scopes, delete the file token.json.\n",
    "SCOPES = [\"https://www.googleapis.com/auth/gmail.readonly\"]\n",
    "FOLDER_NAME = 'ReceiptFolder'\n",
    "\n",
    "\n",
    "\n",
    "def start_service():\n",
    "    creds = None\n",
    "    # The file token.json stores the user's access and refresh tokens, and is\n",
    "    # created automatically when the authorization flow completes for the first\n",
    "    # time.\n",
    "    if os.path.exists(\"token.json\"):\n",
    "        creds = Credentials.from_authorized_user_file(\"token.json\", SCOPES)\n",
    "    # If there are no (valid) credentials available, let the user log in.\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                \"credentials.json\", SCOPES\n",
    "            )\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        # Save the credentials for the next run\n",
    "        with open(\"token.json\", \"w\") as token:\n",
    "            token.write(creds.to_json())\n",
    "\n",
    "    try:\n",
    "    # Call the Gmail API\n",
    "        service = build(\"gmail\", \"v1\", credentials=creds)\n",
    "        results = service.users().labels().list(userId=\"me\").execute()\n",
    "        labels = results.get(\"labels\", [])\n",
    "\n",
    "        if not labels:\n",
    "            print(\"No labels found.\")\n",
    "\n",
    "        # print(\"Labels:\")\n",
    "        for label in labels:\n",
    "        #   print(label[\"name\"])\n",
    "            pass\n",
    "        return service\n",
    "\n",
    "    except HttpError as error:\n",
    "    # TODO(developer) - Handle errors from gmail API.\n",
    "        print(f\"An error occurred: {error}\")\n",
    "\n",
    "\n",
    "def search_messages(service, query):\n",
    "    result = service.users().messages().list(userId='me',q=query).execute()\n",
    "    messages = [ ]\n",
    "    if 'messages' in result:\n",
    "        messages.extend(result['messages'])\n",
    "    while 'nextPageToken' in result:\n",
    "        page_token = result['nextPageToken']\n",
    "        result = service.users().messages().list(userId='me',q=query, pageToken=page_token).execute()\n",
    "        if 'messages' in result:\n",
    "            messages.extend(result['messages'])\n",
    "    return messages\n",
    "\n",
    "def parse_parts(parts, file_count, folder_name=FOLDER_NAME):\n",
    "    \"\"\"\n",
    "    Utility function that parses the content of an email partition\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    if parts:\n",
    "        for part in parts:\n",
    "            filename = part.get(\"filename\")\n",
    "            mimeType = part.get(\"mimeType\")\n",
    "            body = part.get(\"body\")\n",
    "            data = body.get(\"data\")\n",
    "\n",
    "            binary_data = urlsafe_b64decode(data)\n",
    "            if part.get(\"parts\"):\n",
    "                # recursively call this function when we see that a part\n",
    "                # has parts inside\n",
    "                file_count[0] += 1\n",
    "                parse_parts(part.get(\"parts\"), folder_name, file_count)\n",
    "            if mimeType == \"text/html\":\n",
    "                # if the email part is an HTML content\n",
    "                # save the HTML file and optionally open it in the browser\n",
    "                if not filename:\n",
    "                    file_count[0] += 1\n",
    "                    filename = \"index\"+str(file_count[0])+\".html\"\n",
    "                filepath = os.path.join(folder_name, filename)\n",
    "                print(\"Saving HTML to\", filepath)\n",
    "                with open(filepath, \"wb\") as f:\n",
    "                    f.write(binary_data)\n",
    "                # print(binary_data.decode())\n",
    "                return binary_data.decode()\n",
    "\n",
    "        \n",
    "def get_ebay_results(service, msg_id, file_count):\n",
    "    msg = service.users().messages().get(userId='me', id=msg_id).execute()\n",
    "    html_content = parse_parts(msg['payload']['parts'], file_count, 'ReceiptFolder')\n",
    "    headers = msg['payload']['headers']\n",
    "    for header in headers:\n",
    "        if header['name'].lower() == 'date':\n",
    "            date = header['value']\n",
    "        if header['name'].lower() == 'from':\n",
    "            sender = header['value']\n",
    "    \n",
    "    sender = sender.split(' ')[0]\n",
    "        \n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    name_tag = soup.find('a', class_='title')\n",
    "    name = name_tag.string\n",
    "    price_tag = soup.find('p', class_='labelValueValue').find('b')\n",
    "    price = price_tag.string\n",
    "\n",
    "    return sender, date, name, price\n",
    "    \n",
    "def get_walmart_results(service, msg_id, file_count, folder_name = FOLDER_NAME):\n",
    "    msg = service.users().messages().get(userId='me', id=msg_id).execute()\n",
    "    binary_data = urlsafe_b64decode(msg['payload']['body']['data'])\n",
    "    file_count[0] += 1\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    filename = \"index\"+str(file_count[0])+\".html\"\n",
    "    filepath = os.path.join(folder_name, filename)\n",
    "    print(\"Saving HTML to\", filepath)\n",
    "    with open(filepath, \"wb\") as f:\n",
    "        f.write(binary_data)\n",
    "    headers = msg['payload']['headers']\n",
    "    for header in headers:\n",
    "        if header['name'].lower() == 'date':\n",
    "            date = header['value']\n",
    "        if header['name'].lower() == 'from':\n",
    "            sender = header['value']\n",
    "    sender = sender.split('\"')[1].split('.')[0]\n",
    "\n",
    "\n",
    "    return sender, date\n",
    "\n",
    "def get_amazon_results(service, msg_id, file_count, folder_name = FOLDER_NAME):\n",
    "    msg = service.users().messages().get(userId='me', id=msg_id).execute()\n",
    "    html_content = parse_parts(msg['payload']['parts'], file_count, folder_name)\n",
    "    headers = msg['payload']['headers']\n",
    "    for header in headers:\n",
    "        if header['name'].lower() == 'date':\n",
    "            date = header['value']\n",
    "        if header['name'].lower() == 'from':\n",
    "            sender = header['value']\n",
    "    sender = sender.split('\"')[1].split('.')[0]\n",
    "    return sender, date\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    service = start_service()\n",
    "    ebay_search_query = 'from:ebay@ebay.com subject:\"Da, your order is confirmed\"'\n",
    "    walmart_search_query = 'from:help@walmart.com subject:\"Da, thanks for your order\"'\n",
    "    amazon_search_query = 'from:auto-confirm@amazon.com'\n",
    "\n",
    "    query = amazon_search_query\n",
    "\n",
    "    # Call the Gmail API to search for messages\n",
    "    messages = service.users().messages().list(userId='me', q=query).execute()\n",
    "    html_list = []\n",
    "\n",
    "    # Check if any messages match the search criteria\n",
    "    file_count = [0]\n",
    "    if 'messages' in messages:\n",
    "        for message in messages['messages']:\n",
    "            # Get the message details\n",
    "            msg_id = message['id']\n",
    "            # For eBay\n",
    "            if query == ebay_search_query:\n",
    "                sender, date, name, price = get_ebay_results(service, msg_id, file_count)\n",
    "                print('Merchant Name: ', sender)\n",
    "                print('Date: ', date)\n",
    "                print('Item Name: ', name)\n",
    "                print(\"Price: \", price)\n",
    "            # For Walmart\n",
    "            if query == walmart_search_query:\n",
    "                sender, date = get_walmart_results(service, msg_id, file_count)\n",
    "                print('Merchant Name: ', sender)\n",
    "                print('Date: ', date)\n",
    "\n",
    "\n",
    "            # For amazon\n",
    "            if query == amazon_search_query:\n",
    "                sender, date = get_amazon_results(service, msg_id, file_count)\n",
    "                print('Merchant Name: ', sender)\n",
    "                print('Date: ', date)\n",
    "            \n",
    "            # Avoid having too many queries\n",
    "            if file_count[0] >= 10:\n",
    "                break\n",
    "\n",
    "\n",
    "    else:\n",
    "        print('No messages found matching the search criteria.')\n",
    "\n",
    "\n",
    "    # Parse the date string into a datetime object\n",
    "    # date = datetime.strptime(date_str, '%a, %d %b %Y %H:%M:%S %z')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a625d7",
   "metadata": {},
   "source": [
    "## SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c118a22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Item:  \n",
      "3.5mm Jack To 2 Rca Stereo Audio Cable Adapter 6ft 10...\n",
      "\n",
      "Price:  \n",
      "$5.07\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html_list[0], 'html.parser')\n",
    "\n",
    "name_tag = soup.find('a', class_='title')\n",
    "price_tags = soup.find_all('td', class_=\"item\")\n",
    "# print(f'Merchant name: {sender.split(\" \")[0]}')\n",
    "print()\n",
    "print('Item: ', name_tag.string)\n",
    "print('Price: ',price_tags[-1].string)\n",
    "# print('Date: ', msg['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cab7261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$4.66\n"
     ]
    }
   ],
   "source": [
    "with open('ReceiptFolder/index1.html', 'r', encoding='utf-8') as file:\n",
    "    html_string = file.read()\n",
    "\n",
    "soup = BeautifulSoup(html_string,'html.parser')\n",
    "price_tag = soup.find('p', class_='labelValueValue').find('b')\n",
    "print(price_tag.string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "d2b7162d12184ad2d65b0ca95fafc4e9ac2d55419d92e62c3d64ed256c3de9ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
